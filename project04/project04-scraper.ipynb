{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from time import sleep\n",
    "import random\n",
    "from __future__ import print_function\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data analyst\n",
      "0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, business analyst\n",
      "0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, data scientist\n",
      "0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, data engineer\n",
      "0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, data architect\n",
      "0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, database administrator\n",
      "0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, "
     ]
    }
   ],
   "source": [
    "# Search for all of the possible permutations of data science jobs\n",
    "# Pull from Indeed.com\n",
    "\n",
    "search_list = ['data+analyst','business+analyst','data+scientist','data+engineer','data+architect','database+administrator']\n",
    "\n",
    "job_ids = []\n",
    "\n",
    "for title in search_list:\n",
    "    \n",
    "    test = \"https://www.indeed.com.sg/jobs?q={}&l=Singapore&jt=fulltime&start=\".format(title)\n",
    "        \n",
    "    sleep(random.randint(10, 20))\n",
    "    \n",
    "    for page in range(0,200,10): \n",
    "        \n",
    "        #print('Parsing page {}'.format(page))\n",
    "        \n",
    "        url = test + '{}'.format(page)\n",
    "        \n",
    "        # make request for that page\n",
    "        sauce = requests.get(url).text\n",
    "    \n",
    "        # turn into a BeautifulSoup object\n",
    "        soup = BeautifulSoup(sauce, 'lxml')\n",
    "    \n",
    "        # get the job IDs\n",
    "        for listing in soup.find_all('a', {'href': re.compile(r'jk\\=(\\w+)')}):\n",
    "            job_id = re.findall(r'jk\\=(\\w+)', listing['href'])[0]\n",
    "            job_ids.append(job_id)\n",
    "    \n",
    "        sleep(random.randint(3, 15))\n",
    "        \n",
    "        print('{}, '.format(page), end='')\n",
    "    print(title.replace('+',' '), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1076"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the job ids\n",
    "# pickle.dump(job_ids, open('job_ids.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle the job ids\n",
    "# pickle_off = open('job_ids.p','rb')\n",
    "# job_ids = pickle.load(pickle_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "company_name = []\n",
    "job_descriptions = []\n",
    "\n",
    "no_data = 'NA'\n",
    "\n",
    "for id in job_ids:\n",
    "    \n",
    "    url = \"https://www.indeed.com.sg/viewjob?jk={}\".format(id)\n",
    "    \n",
    "    sauce = requests.get(url).text\n",
    "    soup = BeautifulSoup(sauce, 'lxml')\n",
    "    \n",
    "    print('--', end='')\n",
    "    \n",
    "    sleep(random.randint(2, 5)) # Avoiding the anti-bot mechanism\n",
    "\n",
    "    for i in soup.find_all('table', {'id': 'job-content'}):\n",
    "        \n",
    "        # Extract Job Titles\n",
    "        try:\n",
    "            job_title = i.find('b', {'class': 'jobtitle'}).font.text\n",
    "            titles.append(job_title)\n",
    "        except Exception:\n",
    "            title.append(no_data)\n",
    "        \n",
    "        # Extract Company Name\n",
    "        try:\n",
    "            company = i.find('span', {'class': 'company'}).text\n",
    "            company_name.append(company)\n",
    "        except Exception:\n",
    "            company_name.append(no_data)\n",
    "    \n",
    "        # Extract Job Description\n",
    "        try:\n",
    "            job_description = i.find('span', {'class':'summary'}).text.strip()\n",
    "            job_descriptions.append(job_description)\n",
    "        except Exception:\n",
    "            job_descriptions.append(no_data)\n",
    "    \n",
    "        sleep(random.randint(5, 15)) # Avoiding the anti-bot mechanism\n",
    "    \n",
    "    print('>', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of jobs found: 1076\n"
     ]
    }
   ],
   "source": [
    "print('Total number of items found: {}'.format(len(titles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of jobs found: 1066\n"
     ]
    }
   ],
   "source": [
    "print('Total number of items found: {}'.format(len(company_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of jobs found: 1076\n"
     ]
    }
   ],
   "source": [
    "print('Total number of items found: {}'.format(len(job_descriptions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "df = pd.DataFrame({'id': job_ids,'title': titles,'description': job_descriptions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pickle the extracted info\n",
    "# pickle.dump(df, open('df_0804.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dubbed “The Most Innovative Streaming Video Se...</td>\n",
       "      <td>2abc0718a6987824</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title: Data Analyst\\n\\nRole:\\n\\nReporting to t...</td>\n",
       "      <td>c95dd846041ca1c5</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the job ?\\n\\n\\nThe role will involve m...</td>\n",
       "      <td>59df81c8a00dc826</td>\n",
       "      <td>Junior Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - (180000E0)\\nDescription\\n\\nUnde...</td>\n",
       "      <td>6d9971d09cb788a6</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Your Responsibilities :\\n\\nThe Role\\n\\n\\nIn th...</td>\n",
       "      <td>b4c4860763098784</td>\n",
       "      <td>Data Insights Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description                id  \\\n",
       "0  Dubbed “The Most Innovative Streaming Video Se...  2abc0718a6987824   \n",
       "1  Title: Data Analyst\\n\\nRole:\\n\\nReporting to t...  c95dd846041ca1c5   \n",
       "2  What is the job ?\\n\\n\\nThe role will involve m...  59df81c8a00dc826   \n",
       "3  Data Analyst - (180000E0)\\nDescription\\n\\nUnde...  6d9971d09cb788a6   \n",
       "4  Your Responsibilities :\\n\\nThe Role\\n\\n\\nIn th...  b4c4860763098784   \n",
       "\n",
       "                   title  \n",
       "0           Data Analyst  \n",
       "1           Data Analyst  \n",
       "2    Junior Data Analyst  \n",
       "3           Data Analyst  \n",
       "4  Data Insights Analyst  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'].duplicated(keep='first').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='id', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pickle the extracted info\n",
    "# pickle.dump(df, open('df_0804.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check against already scraped data\n",
    "#\n",
    "# df = df[~df['your column'].isin(['list of strings'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to csv instead\n",
    "# df.to_csv('scraped_0804.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving to a SQL file\n",
    "# connection = sqlite3.connect('job_scraped.db.sqlite')\n",
    "# df.to_sql(name = 'jobs', con = connection, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
