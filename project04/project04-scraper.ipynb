{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from time import sleep\n",
    "import random\n",
    "from __future__ import print_function\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing data analyst 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, Parsing business analyst 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, Parsing data scientist 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, Parsing data engineer 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, Parsing data architect 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, "
     ]
    }
   ],
   "source": [
    "# Search for all of the possible permutations of data science jobs\n",
    "# Pull from Indeed.com\n",
    "\n",
    "search_list = ['data+analyst','business+analyst','data+scientist','data+engineer','data+architect']\n",
    "\n",
    "job_ids = []\n",
    "\n",
    "for title in search_list:\n",
    "    \n",
    "    print('Parsing {} '.format(title.replace('+',' ')), end='')\n",
    "    \n",
    "    test = \"https://www.indeed.com.sg/jobs?q={}&l=Singapore&jt=fulltime&start=\".format(title)\n",
    "        \n",
    "    sleep(random.randint(10, 20))\n",
    "    \n",
    "    for page in range(0,110,10): # Change this to make it more managable\n",
    "        \n",
    "        #print('Parsing page {}'.format(page))\n",
    "        \n",
    "        url = test + '{}'.format(page)\n",
    "        \n",
    "        # make request for that page\n",
    "        sauce = requests.get(url).text\n",
    "    \n",
    "        # turn into a BeautifulSoup object\n",
    "        soup = BeautifulSoup(sauce, 'lxml')\n",
    "    \n",
    "        # get the job IDs\n",
    "        for listing in soup.find_all('a', {'href': re.compile(r'jk\\=(\\w+)')}):\n",
    "            job_id = re.findall(r'jk\\=(\\w+)', listing['href'])[0]\n",
    "            job_ids.append(job_id)\n",
    "    \n",
    "        sleep(random.randint(3, 15))\n",
    "        \n",
    "        print('{}, '.format(page), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all duplicates\n",
    "job_ids = list(set(job_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the job ids\n",
    "# pickle.dump(job_ids, open('job_ids_1604.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle the job ids\n",
    "# pickle_off = open('job_ids_1604.p','rb')\n",
    "# job_ids = pickle.load(pickle_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(job_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8c2659cb1181066d',\n",
       " 'd5073c0120205a65',\n",
       " '68122412ba6a2c91',\n",
       " '2abc0718a6987824',\n",
       " 'fe856e889c920d10']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->-->"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "company_name = []\n",
    "job_descriptions = []\n",
    "\n",
    "#no_data = 'NA'\n",
    "\n",
    "for id in job_ids:\n",
    "    \n",
    "    url = \"https://www.indeed.com.sg/viewjob?jk={}\".format(id)\n",
    "    \n",
    "    sauce = requests.get(url).text\n",
    "    soup = BeautifulSoup(sauce, 'lxml')\n",
    "    \n",
    "    print('--', end='')\n",
    "    \n",
    "    sleep(random.randint(2, 5)) # Avoiding the anti-bot mechanism\n",
    "\n",
    "    for i in soup.find_all('table', {'id': 'job-content'}):\n",
    "        \n",
    "        # Extract Job Titles\n",
    "        try:\n",
    "            job_title = i.find('b', {'class': 'jobtitle'}).font.text\n",
    "            titles.append(job_title)\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        # Extract Company Name\n",
    "        try:\n",
    "            company = i.find('span', {'class': 'company'}).text\n",
    "            company_name.append(company)\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "        # Extract Job Description\n",
    "        try:\n",
    "            job_description = i.find('span', {'class':'summary'}).text.strip()\n",
    "            job_descriptions.append(job_description)\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "        #sleep(random.randint(2, 5)) # Avoiding the anti-bot mechanism\n",
    "    \n",
    "    print('>', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items found: 490\n"
     ]
    }
   ],
   "source": [
    "print('Total number of items found: {}'.format(len(titles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items found: 375\n"
     ]
    }
   ],
   "source": [
    "print('Total number of items found: {}'.format(len(company_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items found: 490\n"
     ]
    }
   ],
   "source": [
    "print('Total number of items found: {}'.format(len(job_descriptions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Architect - Singapore',\n",
       " u'ETL Lead',\n",
       " u'Senior Data Architect - 6mth RENEWABLE contract - Healthcare IT Leader',\n",
       " u'Lead Solution Architect',\n",
       " u'Technical Architect']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8039003bcb3728af',\n",
       " '497f563077c23137',\n",
       " 'bc2a2b73b04b9b97',\n",
       " '8e77b14e4ea3fcf6',\n",
       " '89e391ae29af6ce8']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_ids[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "df = pd.DataFrame({'id': job_ids,'title': titles,'description': job_descriptions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Includes jobs responsible for a variety of act...</td>\n",
       "      <td>8c2659cb1181066d</td>\n",
       "      <td>Pricing Analyst - Asia Pacific Business and Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Position Summary:\\n\\n\\nThis position reports t...</td>\n",
       "      <td>d5073c0120205a65</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Are you curious? Do you love data? Are you are...</td>\n",
       "      <td>68122412ba6a2c91</td>\n",
       "      <td>Data &amp; Reporting Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dubbed “The Most Innovative Streaming Video Se...</td>\n",
       "      <td>2abc0718a6987824</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do you have a knack for analyzing business pro...</td>\n",
       "      <td>fe856e889c920d10</td>\n",
       "      <td>Business Data Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description                id  \\\n",
       "0  Includes jobs responsible for a variety of act...  8c2659cb1181066d   \n",
       "1  Position Summary:\\n\\n\\nThis position reports t...  d5073c0120205a65   \n",
       "2  Are you curious? Do you love data? Are you are...  68122412ba6a2c91   \n",
       "3  Dubbed “The Most Innovative Streaming Video Se...  2abc0718a6987824   \n",
       "4  Do you have a knack for analyzing business pro...  fe856e889c920d10   \n",
       "\n",
       "                                               title  \n",
       "0  Pricing Analyst - Asia Pacific Business and Ma...  \n",
       "1                                       Data Analyst  \n",
       "2                           Data & Reporting Analyst  \n",
       "3                                       Data Analyst  \n",
       "4                              Business Data Analyst  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'].duplicated(keep='first').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop_duplicates(subset='id', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check against already mined IDs\n",
    "mined_ids = pickle.load(open('mined_ids.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check against already scraped data\n",
    "#\n",
    "df = df[~df['id'].isin(mined_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to csv instead\n",
    "df.to_csv('scraped_1604_2.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving to a SQL file\n",
    "connection = sqlite3.connect('job_scraped.db.sqlite')\n",
    "df.to_sql(name = 'jobs', con = connection, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(mined_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add latest mined job_ids into the mined_job_ids\n",
    "mined_ids.extend(df['id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(mined_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the job ids\n",
    "pickle.dump(mined_ids, open('mined_ids.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next part is the second mining for company names for the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = []\n",
    "\n",
    "for id in job_ids:\n",
    "    \n",
    "    url = \"https://www.indeed.com.sg/viewjob?jk={}\".format(id)\n",
    "    \n",
    "    sauce = requests.get(url).text\n",
    "    soup = BeautifulSoup(sauce, 'lxml')\n",
    "    \n",
    "    print('--', end='')\n",
    "    \n",
    "    sleep(random.randint(1, 3)) # Avoiding the anti-bot mechanism\n",
    "\n",
    "    for i in soup.find_all('table', {'id': 'job-content'}):\n",
    "        \n",
    "        # Extract Company Name\n",
    "        try:\n",
    "            company = i.find('span', {'class': 'company'}).text\n",
    "            company_name.append(company)\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "        #sleep(random.randint(2, 5)) # Avoiding the anti-bot mechanism\n",
    "    \n",
    "    print('>', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(company_name, open('company_names.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
